{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847adbb7-db76-4977-981e-bb4bb638709c",
   "metadata": {},
   "source": [
    "Q1. Calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation\n",
    "of 5 using Python. Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc213713-187e-462a-ae87-fbc988c5bf7e",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of two or more groups to determine if there are significant differences among them. To ensure the validity of ANOVA results, certain assumptions need to be met. Violations of these assumptions can affect the accuracy and reliability of the ANOVA analysis. The three main assumptions for ANOVA are:\n",
    "\n",
    "1. Independence: The observations within each group should be independent of each other. This means that the data points in one group should not be influenced by or related to the data points in another group. Violations of this assumption can occur when there is dependency or correlation among the observations, such as in repeated measures or matched-pairs designs.\n",
    "\n",
    "2. Normality: The data within each group should follow a normal distribution. Normality assumption means that the residuals (differences between observed values and group means) should be normally distributed. Violations of normality occur when the data are significantly skewed or have heavy tails, deviating from the bell-shaped curve. This can affect the accuracy of the p-values and confidence intervals obtained from ANOVA.\n",
    "\n",
    "3. Homogeneity of Variance: The variances within each group should be approximately equal. This assumption is known as homoscedasticity. Violations of this assumption, called heteroscedasticity, occur when the variability in one group is significantly different from the variability in other groups. Heteroscedasticity can lead to biased results and affect the interpretation of the ANOVA analysis.\n",
    "\n",
    "Examples of violations impacting the validity of ANOVA results:\n",
    "\n",
    "1. Non-independence: If the observations within groups are not independent, such as when measurements are taken from the same individual over time, it violates the independence assumption. This violation can lead to correlated errors and inflated significance levels.\n",
    "\n",
    "2. Non-normality: When the data within groups are not normally distributed, it can impact the validity of p-values and confidence intervals. For example, if the data are heavily skewed or have outliers, it can lead to incorrect conclusions regarding group differences.\n",
    "\n",
    "3. Heteroscedasticity: When the variability within groups is not equal, it violates the assumption of homogeneity of variance. This violation can affect the precision of estimates and lead to incorrect inferences about group differences. For instance, if one group has significantly higher variance than others, it may have a larger influence on the ANOVA results.\n",
    "\n",
    "It's important to assess these assumptions before conducting ANOVA. If the assumptions are violated, alternative analysis methods or transformations of the data might be necessary. Additionally, non-parametric tests, which are more robust to violations of assumptions, can be considered as alternatives to ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768ab2e-88b4-43b3-a1dd-6c72edbb4923",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491180f2-5135-481c-9aa5-c7f7f6e92a5f",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012de64f-69af-4738-83bd-fd8d3e28c6b0",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to analyze the differences between group means. There are three main types of ANOVA:\n",
    "\n",
    "1. One-Way ANOVA: This type of ANOVA is used when there is one independent variable (also called a factor) with two or more levels, and a continuous dependent variable. The one-way ANOVA is used to determine if there are any statistically significant differences between the means of the different levels of the independent variable. For example, you might use a one-way ANOVA to analyze the effect of different doses of a drug on blood pressure, where the independent variable is the drug dose (with levels such as low, medium, and high), and the dependent variable is the blood pressure measurement.\n",
    "\n",
    "2. Two-Way ANOVA: In two-way ANOVA, there are two independent variables (factors), and the dependent variable is continuous. This type of ANOVA is used to analyze the effects of two independent variables and their interactions on the dependent variable. For example, you might use a two-way ANOVA to study the effects of both gender and treatment type on the outcome of a medical procedure. The independent variables would be gender (male/female) and treatment type (A/B), and the dependent variable would be the outcome measure.\n",
    "\n",
    "3. Factorial ANOVA: Factorial ANOVA is an extension of two-way ANOVA that allows for the analysis of multiple independent variables (factors) and their interactions. It is used when there are two or more independent variables, each with two or more levels, and a continuous dependent variable. Factorial ANOVA helps to examine how different factors, as well as their interactions, influence the dependent variable. For example, you might use factorial ANOVA to analyze the effects of age (young/old) and exercise type (A/B/C) on cardiovascular fitness.\n",
    "\n",
    "These three types of ANOVA provide different levels of complexity and flexibility in analyzing the relationships between variables in various experimental designs. The choice of ANOVA type depends on the specific research question, the number of independent variables, and the design of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7fe27-1fe2-442b-9990-ddf2b4958328",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acec684-dfcf-48b9-919d-91939ae4fe94",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc6c51-de1f-436f-8cf2-df5ed7c0515a",
   "metadata": {},
   "source": [
    "#Answer The partitioning of variance in ANOVA refers to the division of the total variance observed in the data into different components that can be attributed to different sources. This partitioning allows for a systematic examination of the variability in the data and helps determine the relative contributions of various factors or sources of variation.\n",
    "\n",
    "In ANOVA, the total variance in the data is decomposed into two main components: \n",
    "\n",
    "1. Between-group variance (or treatment effect): This component of variance represents the variability between different groups or levels of the independent variable(s). It indicates the extent to which the means of the groups differ from each other. If the between-group variance is large relative to the within-group variance, it suggests that there are significant differences between the groups.\n",
    "\n",
    "2. Within-group variance (or error variance): This component of variance represents the variability within each group or level of the independent variable(s). It captures the random variability or noise within the groups that is not explained by the independent variable(s). It is also referred to as the error term because it represents the unexplained variability in the model.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. Identifying significant effects: By comparing the between-group variance with the within-group variance, ANOVA allows us to determine if there are statistically significant differences between the groups. If the between-group variance is large compared to the within-group variance, it suggests that the independent variable(s) has a significant effect on the dependent variable.\n",
    "\n",
    "2. Quantifying effect sizes: The partitioning of variance provides information about the magnitude of the effects. Effect sizes, such as eta-squared or partial eta-squared, can be calculated based on the ratio of between-group variance to total variance. These effect sizes indicate the proportion of the total variance that is accounted for by the independent variable(s).\n",
    "\n",
    "3. Assessing the validity of the model: Understanding the partitioning of variance allows us to evaluate the adequacy of the ANOVA model. If the within-group variance is high relative to the between-group variance, it suggests that there may be unexplained variability or other factors influencing the dependent variable that are not accounted for in the model.\n",
    "\n",
    "4. Designing future studies: Knowledge of the partitioning of variance can guide researchers in designing future studies. By understanding the relative contributions of different sources of variation, researchers can determine the sample size needed to detect significant effects or to estimate effect sizes accurately.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA helps us understand the sources of variability in the data, identify significant effects, quantify effect sizes, assess model validity, and inform the design of future studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68aa9b-06e7-48ba-9454-ab662e3c7fc2",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d8454-0f91-4c58-9047-9330eaa2c9b0",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01c6029-65e5-4fe4-aa1a-cd5c9feb57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 354.93333333333334\n",
      "SSE: 320.1333333333333\n",
      "SSR: 34.80000000000001\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = [10, 12, 15, 13, 11]\n",
    "group2 = [18, 20, 22, 19, 21]\n",
    "group3 = [8, 9, 7, 11, 10]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the SST (Total Sum of Squares)\n",
    "grand_mean = np.mean(data)\n",
    "sst = np.sum((data - grand_mean) ** 2)\n",
    "\n",
    "# Calculate the SSE (Explained Sum of Squares)\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "sse = np.sum([len(group) * (group_mean - grand_mean) ** 2 for group, group_mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate the SSR (Residual Sum of Squares)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbaf43-6ff9-49ad-b189-2a56c6f188e8",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dbde1-120b-428e-9820-73b17987c381",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67726a7-8ae8-46db-b04c-93fda859241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 8.166666666666671\n",
      "Main Effect B: 42.666666666666664\n",
      "Interaction Effect: 0.24999999999999645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data for two factors (A and B) and the response variable (Y)\n",
    "data = {'A': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'B': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "        'Y': [4, 7, 9, 5, 8, 10, 6, 9, 12]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "model = ols('Y ~ A + B + A:B', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_A = anova_table.loc['A', 'sum_sq'] / anova_table.loc['A', 'df']\n",
    "main_effect_B = anova_table.loc['B', 'sum_sq'] / anova_table.loc['B', 'df']\n",
    "interaction_effect = anova_table.loc['A:B', 'sum_sq'] / anova_table.loc['A:B', 'df']\n",
    "\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd56842-96dd-463e-9a53-abe5f7acc2c6",
   "metadata": {},
   "source": [
    "                       -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cfcd8a-e250-42a7-8424-c3a5f8fe7a69",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b3f37-4b5d-408b-9b5d-2fba80aac85a",
   "metadata": {},
   "source": [
    "In the scenario you described, conducting a one-way ANOVA resulted in an F-statistic of 5.23 and a p-value of 0.02. To interpret these results, we need to consider the significance of the F-statistic and the p-value.\n",
    "\n",
    "1. Significance of the F-statistic:\n",
    "The F-statistic is a ratio of two variances: the between-group variance to the within-group variance. It measures the extent to which the group means differ from each other relative to the variability within the groups. In your case, the F-statistic of 5.23 suggests that there is some evidence of differences between the groups.\n",
    "\n",
    "2. Significance of the p-value:\n",
    "The p-value represents the probability of observing the obtained F-statistic (or a more extreme value) if the null hypothesis is true. In this case, the null hypothesis assumes that there are no significant differences between the group means. A p-value of 0.02 indicates that there is a 2% probability of obtaining the observed F-statistic by chance alone under the null hypothesis.\n",
    "\n",
    "Interpreting the results:\n",
    "\n",
    "Given the obtained F-statistic and the p-value, we can draw the following conclusions:\n",
    "\n",
    "1. Differences between the groups: The obtained F-statistic of 5.23 suggests that there are statistically significant differences between the group means. However, it does not provide information about the direction or magnitude of these differences.\n",
    "\n",
    "2. Rejecting the null hypothesis: The p-value of 0.02 is less than the conventional significance level of 0.05. Therefore, we can reject the null hypothesis and conclude that there are significant differences between the groups.\n",
    "\n",
    "3. Practical significance: While the statistical test indicates that there are significant differences, it is also important to consider the practical significance or the real-world implications of these differences. The magnitude of the differences and their practical relevance should be evaluated in light of the specific context of the study.\n",
    "\n",
    "In summary, based on the F-statistic and p-value obtained in the one-way ANOVA, you can conclude that there are statistically significant differences between the groups. However, further analysis and interpretation are necessary to understand the nature and practical significance of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195c9bd-aba6-49ad-a195-6b541eb54fb2",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f5010-8426-42d8-88ce-318675d1395c",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3b274-8e9c-499c-9f35-774a7186cd67",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration to ensure valid and reliable results. There are several methods to handle missing data in this context, and the choice of method can have potential consequences. Here are some commonly used approaches:\n",
    "\n",
    "1. Complete Case Analysis (Listwise deletion): This approach involves excluding any participant or case with missing data from the analysis. It only uses complete cases for the analysis, discarding incomplete cases. The main consequence of this method is a reduction in sample size, which can lead to decreased statistical power and potentially biased results if the missingness is related to the variables being analyzed.\n",
    "\n",
    "2. Pairwise Deletion (Available Case Analysis): This method uses all available data for each comparison in the analysis. It analyzes each participant's available data points while excluding missing data points from specific comparisons. This approach maximizes the use of available data, but it can result in different sample sizes for different comparisons, which may affect the precision and reliability of the estimates.\n",
    "\n",
    "3. Mean Substitution (Imputation): Mean imputation replaces missing data with the mean value of the variable. In repeated measures ANOVA, this means replacing missing values within a participant across time points with the participant's mean score. This method assumes that the missing values are missing completely at random (MCAR) and can introduce bias if the data are missing systematically or if the relationship between missingness and the variable is important.\n",
    "\n",
    "4. Last Observation Carried Forward (LOCF): LOCF imputes missing data with the value of the last observed measurement. This approach assumes that the participant's missing value would be the same as the most recent measurement. However, LOCF may not accurately capture the true values and can lead to biased estimates, particularly if there is substantial variability within participants.\n",
    "\n",
    "5. Multiple Imputation: Multiple imputation creates multiple plausible values for each missing data point based on the observed data. It accounts for the uncertainty associated with missing values and allows for valid statistical inference. Multiple imputation methods impute missing data based on patterns and relationships in the data, but it requires assumptions about the missing data mechanism.\n",
    "\n",
    "The consequences of using different methods to handle missing data include potential biases in parameter estimates, standard errors, and hypothesis tests. The choice of method depends on the missing data pattern, the assumptions made about the missingness mechanism, and the specific goals of the analysis. It is crucial to consider the limitations and potential biases associated with each method and to perform sensitivity analyses to evaluate the robustness of the results across different missing data handling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3b616-2f74-4a73-88b6-1f04edafdd88",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06e381-01a3-4462-922f-7719d66e0324",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0614a0-f7d2-4b54-b25e-7daf82891a37",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a statistically significant result, post-hoc tests are often used to determine which specific groups differ significantly from each other. Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) Test: This test compares all possible pairs of group means and controls the familywise error rate. It is appropriate when you have equal sample sizes and homogeneous variances across groups.\n",
    "\n",
    "2. Bonferroni Correction: Bonferroni correction adjusts the significance level of individual comparisons to maintain a desired familywise error rate. It is a conservative method that divides the overall significance level (e.g., 0.05) by the number of comparisons.\n",
    "\n",
    "3. Dunnett's Test: Dunnett's test is used when you have one control group and want to compare it to multiple treatment groups. It controls the experimentwise error rate by comparing each treatment group to the control group.\n",
    "\n",
    "4. Fisher's Least Significant Difference (LSD) Test: This test compares the means of all possible pairs of groups. It does not control the familywise error rate, making it less conservative than other tests. It is typically used for exploratory purposes or when there is a specific hypothesis about pairwise differences.\n",
    "\n",
    "5. Scheffe's Test: Scheffe's test is a conservative post-hoc test that can be used in situations where there are unequal sample sizes and/or variances across groups. It controls the familywise error rate for all possible pairwise comparisons.\n",
    "\n",
    "Example scenario:\n",
    "Let's say you conducted a study comparing the effectiveness of three different treatment approaches (A, B, and C) for reducing symptoms of a specific medical condition. After performing an ANOVA on the data, you found a significant difference among the treatment groups. In this case, you would need a post-hoc test to determine which specific treatment groups differ significantly from each other.\n",
    "\n",
    "For example, you could use Tukey's HSD test to compare the means of all possible pairs of treatment groups. It would provide you with a set of confidence intervals and p-values for each comparison, allowing you to identify the specific pairs of treatments that are significantly different from each other. This information would help you understand which treatment approaches are more effective than others in reducing symptoms of the medical condition.\n",
    "\n",
    "Overall, post-hoc tests are necessary to perform multiple pairwise comparisons after obtaining a significant result in an ANOVA, enabling a more detailed understanding of the specific group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf10c1f-245e-40f7-bc2c-e086a92eea91",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599fcf3-4f03-4f97-8faa-89201bd76dac",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34812e4a-1cb4-4480-9f7f-1cc28d8c9a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.0004079374570408328\n",
      "p-value: 0.9995921468774791\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for weight loss in three diets\n",
    "diet_A = [2, 3, 4, 2, 5, 3, 4, 6, 2, 4, 3, 5, 4, 3, 2, 4, 5, 3, 4, 6, 2, 3, 4, 3, 5, 4, 2, 4, 3, 5, 3, 4, 2, 5, 3, 4, 6, 4, 3, 2, 4, 5, 4, 3, 2, 4, 5, 6, 4]\n",
    "diet_B = [3, 4, 5, 3, 2, 4, 3, 5, 4, 2, 4, 3, 5, 4, 2, 3, 4, 5, 3, 4, 6, 2, 3, 4, 3, 5, 4, 2, 4, 3, 5, 3, 4, 2, 5, 3, 4, 6, 4, 3, 2, 4, 5, 4, 3, 2, 4, 5, 6, 4]\n",
    "diet_C = [4, 5, 3, 4, 2, 3, 4, 5, 3, 2, 4, 3, 5, 4, 2, 3, 4, 5, 3, 4, 6, 2, 3, 4, 3, 5, 4, 2, 4, 3, 5, 3, 4, 2, 5, 3, 4, 6, 4, 3, 2, 4, 5, 4, 3, 2, 4, 5, 6, 4]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90460ed0-cbfa-4139-ac2f-9501c100a4ff",
   "metadata": {},
   "source": [
    "To interpret the results:\n",
    "\n",
    "If the obtained p-value is less than the chosen significance level (e.g., 0.05), it suggests that there are significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "If the p-value is greater than the significance level, it implies that there is insufficient evidence to conclude significant differences between the mean weight loss of the diets.\n",
    "\n",
    "In the context of the example data, let's say the analysis resulted in an F-statistic of 3.18 and a p-value of 0.045. With a significance level of 0.05, since the p-value is less than 0.05, you would conclude that there are significant differences between the mean weight loss of the three diets A, B, and C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f3d9c-e193-4f33-bc16-1497481e05a2",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b51f1-1489-47ad-8bad-d59e3b9aa53c",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5e424f-a3fe-4de6-b70f-6b996280daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2022.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                 20.095357   2.0  1.331308  0.282945\n",
      "C(Experience)               22.123134   1.0  2.931295  0.099772\n",
      "C(Software):C(Experience)    3.437977   2.0  0.227764  0.798013\n",
      "Residual                   181.133333  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Time': [12, 14, 15, 18, 10, 11, 9, 16, 14, 17, 10, 11, 13, 12, 15, 16, 9, 10, 11, 14, 13, 15, 19, 17, 13, 12, 11, 15, 16, 17],\n",
    "    'Software': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'],\n",
    "    'Experience': ['Novice', 'Experienced'] * 15\n",
    "})\n",
    "\n",
    "# Convert Experience column to categorical type\n",
    "data['Experience'] = data['Experience'].astype('category')\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08aa0ad-619b-421c-a185-2eb8fa35e196",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "we can interpret the results based on the p-values as follows:\n",
    "\n",
    "If the p-value for the main effect of Software is below your chosen significance level (e.g., 0.05), it indicates that there is a significant difference in the average time to complete the task among the software programs.\n",
    "If the p-value for the main effect of Experience is below your significance level, it suggests that there is a significant difference in the average time to complete the task between novice and experienced employees.\n",
    "If the p-value for the interaction effect (Software:Experience) is below your significance level, it suggests that the effect of software programs on the time to complete the task depends on the experience level of the employees. In other words, the difference in average time among the software programs varies depending on whether the employee is a novice or experienced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27a355-3583-4a73-87a7-10da1be0807d",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e5e5e-ccd3-4472-8fa2-7130e4015ccf",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2811dc-dab8-4281-a78a-35ef8abba02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 3.1204197640191387\n",
      "p-value: 0.0023546273994354727\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1    group2    meandiff p-adj   lower   upper  reject\n",
      "-----------------------------------------------------------\n",
      "Control Experimental  -4.1063 0.0024 -6.7168 -1.4958   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for test scores in the control and experimental groups\n",
    "control_group = [75, 80, 85, 90, 78, 82, 88, 92, 80, 85, 88, 95, 77, 82, 87, 93, 76, 81, 86, 92, 79, 84, 89, 96, 83, 88, 94, 97, 80, 85, 90, 98, 79, 84, 89, 94, 82, 87, 92, 100, 78, 83, 88, 95, 81, 86, 91, 98, 77, 82, 87, 94]\n",
    "\n",
    "experimental_group = [80, 85, 90, 95, 79, 84, 89, 94, 81, 86, 91, 96, 78, 83, 88, 93, 77, 82, 87, 92, 76, 81, 86, 91, 75, 80, 85, 90, 74, 79, 84, 89, 73, 78, 83, 88, 72, 77, 82, 87, 71, 76, 81, 86, 70, 75, 80, 85, 69, 74, 79]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant (p-value < 0.05)\n",
    "if p_value < 0.05:\n",
    "    # Conduct post-hoc test (optional)\n",
    "    posthoc_tukey = pairwise_tukeyhsd(np.concatenate([control_group, experimental_group]), np.concatenate([['Control']*len(control_group), ['Experimental']*len(experimental_group)]))\n",
    "    print(posthoc_tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cd8b4-ea0e-40d4-8b62-417dfc3e1cec",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96f893-1433-472b-bfe5-efb4cc65bff7",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16330a8d-4229-4028-92de-95ccee52ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq    df          F        PR(>F)\n",
      "C(Store)   418.155556   2.0  17.577484  3.876618e-07\n",
      "Residual  1034.833333  87.0        NaN           NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B  -4.4333    0.0 -6.5567  -2.31   True\n",
      "     A      C   0.2667 0.9518 -1.8567   2.39  False\n",
      "     B      C      4.7    0.0  2.5766 6.8234   True\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data for daily sales in Store A, Store B, and Store C\n",
    "store_A = [100, 105, 98, 102, 108, 105, 103, 100, 99, 105, 102, 106, 105, 108, 107, 110, 108, 103, 105, 109, 112, 115, 113, 110, 105, 108, 102, 100, 106, 109]\n",
    "store_B = [98, 100, 103, 102, 101, 104, 102, 100, 99, 97, 98, 96, 98, 102, 100, 99, 101, 104, 102, 100, 99, 98, 102, 104, 106, 108, 105, 102, 101, 104]\n",
    "store_C = [105, 102, 100, 106, 110, 112, 108, 105, 103, 102, 108, 106, 109, 105, 102, 108, 107, 106, 105, 102, 103, 108, 106, 110, 112, 108, 105, 103, 102, 108]\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "data = pd.DataFrame({'Sales': np.concatenate([store_A, store_B, store_C]),\n",
    "                     'Store': np.repeat(['A', 'B', 'C'], len(store_A)),\n",
    "                     'Day': np.tile(range(len(store_A)), 3)})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Sales ~ C(Store)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n",
    "\n",
    "# Check if the results are significant (p-value < 0.05)\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    # Conduct post-hoc test (optional)\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "    print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94e838-a6ed-4330-9a33-ee5227bd19e0",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
